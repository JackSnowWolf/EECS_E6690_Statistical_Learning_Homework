\documentclass[twoside]{homework}

\usepackage{dsfont} 

\studname{Chong Hu}
\uni{ch3467}
\studmail{ch3467@columbia.edu}
\coursename{Statistical Learning for Biological and Information Systems}
\hwNo{1}

\begin{document}
\maketitle

\section*{P1}
\begin{enumerate}
    \item[(a)] 
    \begin{align*}
        (n-1) S^2 + n\bar{X}^2  &= \sum_{i=1}^{n} (X_i - \bar{X})^2 + n\bar{X}^2 \\
        &=   \sum_{i=1}^{n} (X_i^2 - 2X_i\bar{X} + \bar{X}^2) + n\bar{X}^2 \\
        &= \sum_{i=1}^{} X_i^2 -2n\bar{X} +n(\bar{X})^2 + n\bar{X}^2 \\
        &= \sum_{i=1}^{} X_i^2
    \end{align*}
    Therefore,
    \begin{equation*}
        \sum_{i=1}^{n} X_i^2 = (n-1) S^2 + n\bar{X}^2 
    \end{equation*}
    \item[(b)]
    According to the question, we have
    \begin{equation*}
       \mathrm{Var}[X_i] =  \mathbb{E}[(X_i-\mathbb{E}[X_i])^2] = \sigma^2 \quad  \forall i = 1,2,3,..,,n
    \end{equation*}
    and we can assume,
    \begin{equation*}
        \mathbb{E}[X_i] = \mu
    \end{equation*}
    hence,
    \begin{equation*}
        \mathrm{Var}[X_i] = \mathbb{E}[X_i^2] - \mu^2 = \sigma ^2
    \end{equation*}
    
    Also, we have
    \begin{align*}
        \mathrm{Var}[\bar{X}] &= \frac{\sigma^2}{n} \\
        \mathbb{E}[\bar{X}^2] &= \mathrm{Var}[\bar{X}] + \mathbb{E}[\bar{X}]^2 \\
        &= \frac{\sigma^2}{n} + \mu^2
    \end{align*}
    \begin{align*}
        \mathbb{E}[S^2] &= \mathbb{E}\bigg[\frac{1}{n-1}\sum_{i=1}^{n} (X_i - \bar{X})^2 \bigg]\\
        &= \frac{1}{n-1} \mathbb{E}\bigg[\sum_{i=1}^{n} \bigg( X_i^2 - 2X_i \bar{X} + \bar{X}^2\bigg) \bigg] \\
        &= \frac{1}{n-1} \mathbb{E}\bigg[\sum_{i=1}^{n}  X_i^2  - n \bar{X^2} \bigg] \\
        &= \frac{1}{n-1} \bigg( n(\sigma^2 +\mu^2) - n (\frac{\sigma^2}{n} + \mu^2) \bigg) \\
        &= \sigma^2
    \end{align*}
    \item[(c)] Since $X_i$-s have i.i.d. normal/Gaussian distribution $\mathcal{N}(\mu, \sigma^2)$
    \begin{align*}
        \mathrm{Cov}[\bar{X},  X_i - \bar{X}] &=  \mathrm{Cov}[\bar{X},  X_i ] - \mathrm{Var}[\bar{X}]\\
        &= \frac{1}{n}\mathrm{Cov}[X_i + \sum_{j\neq i}^{}  X_j, X_i] - \frac{\sigma^2}{n} \\
        &= \frac{1}{n}\mathrm{Var}[X_i] - \frac{\sigma^2}{n} \\
        &= 0
    \end{align*}
    therefore, $\bar{X}$ is independent of $X_i-\bar{X}$.
    \item[(d)] Since sample variance
    \begin{equation*}
        S^2 = \frac{1}{n-1} \sum_{i=1}^{n} (X_i - \bar{X})^2
    \end{equation*}
    is a function of $X_i-\bar{X}$, which is independent of $\bar{X}$,
    sample mean is also independent of sample variance.
\end{enumerate}


\section*{P2}
Assume that $\bar{y} = \bar{x}=0$,
then we have,
\begin{equation*}
    R^2 = \frac{\sum_{i=1}^{n}( \hat{y_i})^2}{\sum_{i=1}^{n} y_i^2} = \frac{1}{\sum_{i=1}^{n} y_i^2} \sum_{i=1}^{n} \bigg( \frac{\sum_{i=1}^{n}x_i y_i}{\sum_{i=1}^{n}x_i^2}x_i \bigg)^2 = \frac{1}{\sum_{i=1}^{n} y_i^2}  \bigg( \frac{\sum_{i=1}^{n}x_i y_i}{\sum_{i=1}^{n}x_i^2} \bigg)^2 \sum_{i=1}^{n} x_i^2 = \frac{(\sum_{i=1}^{n} x_i y_i)^2}{\sum_{i=1}^{n} x_i^2 \sum_{i=1}^{n} y_i^2} 
\end{equation*}
and
\begin{equation*}
    r^2 = \frac{(\sum_{i=1}^{n} x_i y_i)^2}{\sum_{i=1}^{n} x_i^2 \sum_{i=1}^{n} y_i^2} 
\end{equation*}.
Hence, $R^2$ = $r^2$
\newpage

\section*{P3}

\newpage

\end{document}